#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èªéŸ³è½‰æ–‡å­—ç¨‹å¼
åŠŸèƒ½ï¼š
1. éŒ„è£½èªéŸ³ä¸¦è½‰æ›ç‚ºæ–‡å­—
2. ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆä¸¦è½‰æ›ç‚ºæ–‡å­—
3. æ”¯æ´ä¸­è‹±æ–‡è­˜åˆ¥
4. å°å‡ºç‚ºdocxæˆ–txtæ ¼å¼
5. AIæ™ºèƒ½æ‘˜è¦åˆ†æ
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import threading
import os
from datetime import datetime
import tempfile
import time
import json
import re

# æ¢ä»¶å°å…¥å¯èƒ½ç¼ºå°‘çš„å¥—ä»¶
try:
    import speech_recognition as sr
    SPEECH_RECOGNITION_AVAILABLE = True
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False
    sr = None

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False

try:
    import wave
    WAVE_AVAILABLE = True
except ImportError:
    WAVE_AVAILABLE = False

try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class SpeechToTextApp:
    def __init__(self, root):
        self.root = root
        self.root.title("èªéŸ³è½‰æ–‡å­—ç¨‹å¼ - å«AIæ‘˜è¦åŠŸèƒ½")
        self.root.geometry("1200x800")  # å¢åŠ çª—å£å¤§å°ä»¥å®¹ç´æ›´å¤šå…§å®¹
        
        # æª¢æŸ¥å¿…è¦å¥—ä»¶
        self.check_dependencies()
        
        # åˆå§‹åŒ–è®Šæ•¸
        self.is_recording = False
        self.is_paused = False  # æ–°å¢æš«åœç‹€æ…‹
        self.recording_thread = None  # éŒ„éŸ³ç·šç¨‹å¼•ç”¨
        self.audio_data = None
        self.recognizer = sr.Recognizer() if SPEECH_RECOGNITION_AVAILABLE else None
        self.microphone = sr.Microphone() if SPEECH_RECOGNITION_AVAILABLE and PYAUDIO_AVAILABLE else None
        self.whisper_model = None
        self.recording_segments = []  # å­˜å„²å¤šæ®µéŒ„éŸ³
        self.recording_start_time = None
        self.pause_start_time = None  # æš«åœé–‹å§‹æ™‚é–“
        self.total_pause_time = 0  # ç¸½æš«åœæ™‚é–“
        self.temp_files = []  # è¿½è¹¤è‡¨æ™‚æª”æ¡ˆ
        self.audio_files = []  # å­˜å„²å¤šå€‹éŸ³è¨Šæª”æ¡ˆçš„è³‡è¨Š [{'path': '', 'name': '', 'order': int}]
        self.current_processing_index = 0  # ç›®å‰è™•ç†çš„æª”æ¡ˆç´¢å¼•
        self.total_elapsed_time = 0  # ç´¯è¨ˆæ™‚é–“ï¼ˆç§’ï¼‰
        self.enable_timestamps = False  # æ˜¯å¦å•Ÿç”¨æ™‚é–“æˆ³
        
        # AIæ‘˜è¦ç›¸é—œè®Šæ•¸
        self.openai_api_key = ""  # OpenAI APIå¯†é‘°
        self.ai_summary_result = ""  # AIæ‘˜è¦çµæœ
        self.enable_ai_summary = False  # æ˜¯å¦å•Ÿç”¨AIæ‘˜è¦
        
        # è¼‰å…¥Whisperæ¨¡å‹
        if WHISPER_AVAILABLE:
            self.load_whisper_model()
        
        # å»ºç«‹UI
        self.create_widgets()
        
        # èª¿æ•´éº¥å…‹é¢¨
        if SPEECH_RECOGNITION_AVAILABLE and PYAUDIO_AVAILABLE:
            self.adjust_microphone()
    
    def check_dependencies(self):
        """æª¢æŸ¥ä¸¦é¡¯ç¤ºç¼ºå°‘çš„å¥—ä»¶"""
        missing_packages = []
        
        if not SPEECH_RECOGNITION_AVAILABLE:
            missing_packages.append("speech_recognition")
        if not PYAUDIO_AVAILABLE:
            missing_packages.append("pyaudio")
        if not DOCX_AVAILABLE:
            missing_packages.append("python-docx")
        if not WHISPER_AVAILABLE:
            missing_packages.append("openai-whisper")
        if not PYDUB_AVAILABLE:
            missing_packages.append("pydub")
        if not OPENAI_AVAILABLE:
            missing_packages.append("openai")
        
        if missing_packages:
            message = f"è­¦å‘Šï¼šä»¥ä¸‹å¥—ä»¶æœªå®‰è£ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ç„¡æ³•ä½¿ç”¨ï¼š\n\n"
            for pkg in missing_packages:
                message += f"â€¢ {pkg}\n"
            message += f"\nå®‰è£å‘½ä»¤ï¼š\n"
            message += f"pip install {' '.join(missing_packages)}\n\n"
            message += f"ç¨‹å¼å°‡ä»¥æœ‰é™åŠŸèƒ½æ¨¡å¼é‹è¡Œã€‚"
            
            # å»¶é²é¡¯ç¤ºæ¶ˆæ¯ï¼Œè®“GUIå®Œå…¨è¼‰å…¥
            self.root.after(1000, lambda: messagebox.showwarning("å¥—ä»¶æª¢æŸ¥", message))
    
    def load_whisper_model(self):
        """è¼‰å…¥Whisperæ¨¡å‹"""
        if not WHISPER_AVAILABLE:
            print("Whisperå¥—ä»¶æœªå®‰è£ï¼Œè·³éæ¨¡å‹è¼‰å…¥")
            return
            
        try:
            print("è¼‰å…¥Whisperæ¨¡å‹ä¸­...")
            self.whisper_model = whisper.load_model("base")
            print("Whisperæ¨¡å‹è¼‰å…¥å®Œæˆ")
        except Exception as e:
            print(f"è¼‰å…¥Whisperæ¨¡å‹å¤±æ•—: {e}")
            self.whisper_model = None
    
    def adjust_microphone(self):
        """èª¿æ•´éº¥å…‹é¢¨"""
        if not SPEECH_RECOGNITION_AVAILABLE or not PYAUDIO_AVAILABLE:
            print("èªéŸ³è­˜åˆ¥å¥—ä»¶æœªå®‰è£ï¼Œè·³ééº¥å…‹é¢¨èª¿æ•´")
            return
            
        try:
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source)
            print("éº¥å…‹é¢¨å·²èª¿æ•´å®Œæˆ")
        except Exception as e:
            print(f"èª¿æ•´éº¥å…‹é¢¨å¤±æ•—: {e}")
    
    def update_record_status(self, text):
        """å®‰å…¨åœ°æ›´æ–°éŒ„éŸ³ç‹€æ…‹"""
        try:
            self.record_status.config(text=text)
        except Exception as e:
            print(f"æ›´æ–°ç‹€æ…‹å¤±æ•—: {e}")
    
    def safe_update_result(self, text):
        """å®‰å…¨åœ°æ›´æ–°çµæœé¡¯ç¤º"""
        try:
            self.text_result.delete(1.0, tk.END)
            self.text_result.insert(tk.END, text)
        except Exception as e:
            print(f"æ›´æ–°çµæœå¤±æ•—: {e}")
    
    def safe_file_cleanup(self, file_path, max_retries=3):
        """å®‰å…¨åœ°æ¸…ç†æª”æ¡ˆï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶"""
        import time
        for attempt in range(max_retries):
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
                return True
            except PermissionError:
                print(f"æª”æ¡ˆæ¸…ç†å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {file_path}")
                time.sleep(0.5)  # ç­‰å¾…0.5ç§’å¾Œé‡è©¦
            except Exception as e:
                print(f"æª”æ¡ˆæ¸…ç†éŒ¯èª¤: {e}")
                break
        return False
    
    def cleanup_temp_files(self):
        """æ¸…ç†æ‰€æœ‰è¿½è¹¤çš„è‡¨æ™‚æª”æ¡ˆ"""
        cleaned_files = []
        failed_files = []
        
        for file_path in self.temp_files[:]:  # ä½¿ç”¨å‰¯æœ¬éæ­·
            if self.safe_file_cleanup(file_path):
                cleaned_files.append(file_path)
                self.temp_files.remove(file_path)
            else:
                failed_files.append(file_path)
        
        if cleaned_files:
            print(f"å·²æ¸…ç† {len(cleaned_files)} å€‹è‡¨æ™‚æª”æ¡ˆ")
        if failed_files:
            print(f"ç„¡æ³•æ¸…ç† {len(failed_files)} å€‹æª”æ¡ˆ: {failed_files}")
        
        return len(failed_files) == 0
    
    def reset_all(self):
        """é‡ç½®æ‰€æœ‰ç‹€æ…‹å’Œæ¸…ç†è³‡æº"""
        try:
            # åœæ­¢éŒ„éŸ³
            if self.is_recording:
                self.is_recording = False
            
            # é‡ç½®éŒ„éŸ³ç‹€æ…‹
            self.is_paused = False
            self.recording_thread = None
            self.pause_start_time = None
            self.total_pause_time = 0
            
            # æ¸…ç©ºéŸ³è¨Šè³‡æ–™
            self.audio_data = None
            self.recording_segments = []
            self.recording_start_time = None
            self.audio_files = []  # æ¸…ç©ºéŸ³è¨Šæª”æ¡ˆåˆ—è¡¨
            self.current_processing_index = 0
            self.total_elapsed_time = 0  # é‡ç½®ç´¯è¨ˆæ™‚é–“
            
            # é‡ç½®AIç›¸é—œç‹€æ…‹
            self.ai_summary_result = ""
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            self.cleanup_temp_files()
            
            # é‡ç½®UIç‹€æ…‹
            self.root.after(0, self.update_record_status, "å·²é‡ç½®")
            self.root.after(0, lambda: self.record_button.config(state="normal"))
            self.root.after(0, lambda: self.pause_button.config(state="disabled"))
            self.root.after(0, lambda: self.resume_button.config(state="disabled"))
            self.root.after(0, lambda: self.stop_button.config(state="disabled"))
            self.root.after(0, lambda: self.clear_audio_files())  # æ¸…ç©ºæª”æ¡ˆåˆ—è¡¨
            self.root.after(0, lambda: self.text_result.delete(1.0, tk.END))
            self.root.after(0, lambda: self.clear_ai_summary())  # æ¸…ç©ºAIæ‘˜è¦
            
            print("ç³»çµ±å·²é‡ç½®")
            return True
            
        except Exception as e:
            print(f"é‡ç½®å¤±æ•—: {e}")
            return False
    
    def create_widgets(self):
        """å»ºç«‹UIå…ƒä»¶"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # æ¨™é¡Œ
        title_label = ttk.Label(main_frame, text="èªéŸ³è½‰æ–‡å­—ç¨‹å¼ - å«AIæ‘˜è¦åŠŸèƒ½", font=("Arial", 16, "bold"))
        title_label.grid(row=0, column=0, columnspan=4, pady=(0, 20))
        
        # å»ºç«‹å·¦å³å…©æ¬„ä½ˆå±€
        left_frame = ttk.Frame(main_frame)
        left_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 10))
        
        right_frame = ttk.Frame(main_frame)
        right_frame.grid(row=1, column=2, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(10, 0))
        
        # ==================== å·¦å´å€åŸŸ ====================
        
        # éŒ„éŸ³å€åŸŸ
        record_frame = ttk.LabelFrame(left_frame, text="èªéŸ³éŒ„è£½", padding="10")
        record_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # éŒ„éŸ³æ§åˆ¶æŒ‰éˆ•å€åŸŸ
        button_frame = ttk.Frame(record_frame)
        button_frame.grid(row=0, column=0, columnspan=2, pady=(0, 10))
        
        self.record_button = ttk.Button(button_frame, text="é–‹å§‹éŒ„éŸ³", command=self.start_recording)
        self.record_button.grid(row=0, column=0, padx=(0, 5))
        
        self.pause_button = ttk.Button(button_frame, text="æš«åœéŒ„éŸ³", command=self.pause_recording, state="disabled")
        self.pause_button.grid(row=0, column=1, padx=(0, 5))
        
        self.resume_button = ttk.Button(button_frame, text="ç¹¼çºŒéŒ„éŸ³", command=self.resume_recording, state="disabled")
        self.resume_button.grid(row=0, column=2, padx=(0, 5))
        
        self.stop_button = ttk.Button(button_frame, text="çµæŸéŒ„éŸ³", command=self.stop_recording, state="disabled")
        self.stop_button.grid(row=0, column=3)
        
        self.record_status = ttk.Label(record_frame, text="æº–å‚™éŒ„éŸ³")
        self.record_status.grid(row=1, column=0, columnspan=2, pady=(5, 0))
        
        # éŒ„éŸ³è¨­å®š
        settings_frame = ttk.Frame(record_frame)
        settings_frame.grid(row=2, column=0, columnspan=2, pady=(10, 0))
        
        ttk.Label(settings_frame, text="éŒ„éŸ³æ¨¡å¼ï¼š").grid(row=0, column=0, sticky=tk.W)
        self.record_mode_var = tk.StringVar(value="continuous")
        ttk.Radiobutton(settings_frame, text="é€£çºŒéŒ„éŸ³", variable=self.record_mode_var, value="continuous").grid(row=0, column=1, padx=(5, 10))
        ttk.Radiobutton(settings_frame, text="å–®å¥éŒ„éŸ³", variable=self.record_mode_var, value="single").grid(row=0, column=2)
        
        # æª”æ¡ˆä¸Šå‚³å€åŸŸ
        upload_frame = ttk.LabelFrame(left_frame, text="éŸ³è¨Šæª”æ¡ˆç®¡ç†", padding="10")
        upload_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        # æª”æ¡ˆæ“ä½œæŒ‰éˆ•
        file_buttons_frame = ttk.Frame(upload_frame)
        file_buttons_frame.grid(row=0, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.upload_button = ttk.Button(file_buttons_frame, text="æ–°å¢éŸ³è¨Šæª”æ¡ˆ", command=self.add_audio_files)
        self.upload_button.grid(row=0, column=0, padx=(0, 10))
        
        self.clear_files_button = ttk.Button(file_buttons_frame, text="æ¸…ç©ºåˆ—è¡¨", command=self.clear_audio_files)
        self.clear_files_button.grid(row=0, column=1, padx=(0, 10))
        
        self.batch_convert_button = ttk.Button(file_buttons_frame, text="æ‰¹æ¬¡è½‰æ›", command=self.batch_convert_files)
        self.batch_convert_button.grid(row=0, column=2)
        
        # æª”æ¡ˆåˆ—è¡¨å€åŸŸ
        list_frame = ttk.Frame(upload_frame)
        list_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(10, 0))
        
        # æª”æ¡ˆåˆ—è¡¨
        columns = ("é †åº", "æª”æ¡ˆåç¨±", "è·¯å¾‘")
        self.file_tree = ttk.Treeview(list_frame, columns=columns, show="headings", height=6)
        
        # è¨­å®šæ¬„ä½æ¨™é¡Œ
        self.file_tree.heading("é †åº", text="é †åº")
        self.file_tree.heading("æª”æ¡ˆåç¨±", text="æª”æ¡ˆåç¨±")
        self.file_tree.heading("è·¯å¾‘", text="æª”æ¡ˆè·¯å¾‘")
        
        # è¨­å®šæ¬„ä½å¯¬åº¦
        self.file_tree.column("é †åº", width=60, anchor=tk.CENTER)
        self.file_tree.column("æª”æ¡ˆåç¨±", width=200)
        self.file_tree.column("è·¯å¾‘", width=250)
        
        # æ²è»¸
        file_scrollbar = ttk.Scrollbar(list_frame, orient="vertical", command=self.file_tree.yview)
        self.file_tree.configure(yscrollcommand=file_scrollbar.set)
        
        # é…ç½®ç¶²æ ¼
        self.file_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        file_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        # é †åºèª¿æ•´æŒ‰éˆ•
        order_frame = ttk.Frame(upload_frame)
        order_frame.grid(row=2, column=0, columnspan=3, pady=(10, 0))
        
        ttk.Button(order_frame, text="ä¸Šç§»", command=self.move_up).grid(row=0, column=0, padx=(0, 10))
        ttk.Button(order_frame, text="ä¸‹ç§»", command=self.move_down).grid(row=0, column=1, padx=(0, 10))
        ttk.Button(order_frame, text="ç§»é™¤é¸ä¸­", command=self.remove_selected).grid(row=0, column=2)
        
        # è­˜åˆ¥å¼•æ“é¸æ“‡
        engine_frame = ttk.LabelFrame(left_frame, text="è­˜åˆ¥å¼•æ“", padding="10")
        engine_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.engine_var = tk.StringVar(value="google")
        ttk.Radiobutton(engine_frame, text="Google (éœ€ç¶²è·¯)", variable=self.engine_var, value="google").grid(row=0, column=0, padx=(0, 10))
        ttk.Radiobutton(engine_frame, text="Whisper (é›¢ç·š)", variable=self.engine_var, value="whisper").grid(row=0, column=1)
        
        # èªè¨€é¸æ“‡
        lang_frame = ttk.LabelFrame(left_frame, text="èªè¨€è¨­å®š", padding="10")
        lang_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.language_var = tk.StringVar(value="zh-TW")
        ttk.Radiobutton(lang_frame, text="ä¸­æ–‡", variable=self.language_var, value="zh-TW").grid(row=0, column=0, padx=(0, 10))
        ttk.Radiobutton(lang_frame, text="è‹±æ–‡", variable=self.language_var, value="en-US").grid(row=0, column=1, padx=(0, 10))
        ttk.Radiobutton(lang_frame, text="è‡ªå‹•", variable=self.language_var, value="auto").grid(row=0, column=2)
        
        # é€²éšé¸é …
        options_frame = ttk.LabelFrame(left_frame, text="é€²éšé¸é …", padding="10")
        options_frame.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # æ™‚é–“æˆ³é¸é …
        self.timestamp_var = tk.BooleanVar(value=False)
        timestamp_check = ttk.Checkbutton(
            options_frame, 
            text="å•Ÿç”¨é€å­—æ™‚é–“æˆ³", 
            variable=self.timestamp_var,
            command=self.toggle_timestamp_option
        )
        timestamp_check.grid(row=0, column=0, sticky=tk.W)
        
        # æ™‚é–“æˆ³æ ¼å¼èªªæ˜
        self.timestamp_info = ttk.Label(
            options_frame, 
            text="æ ¼å¼ï¼š[MM:SS] æˆ– [HH:MM:SS]",
            font=("Arial", 8),
            foreground="gray"
        )
        self.timestamp_info.grid(row=1, column=0, sticky=tk.W, pady=(5, 0))
        
        # AIæ‘˜è¦é¸é …
        self.ai_summary_var = tk.BooleanVar(value=False)
        ai_summary_check = ttk.Checkbutton(
            options_frame,
            text="å•Ÿç”¨AIæ™ºèƒ½æ‘˜è¦",
            variable=self.ai_summary_var,
            command=self.toggle_ai_summary_option
        )
        ai_summary_check.grid(row=2, column=0, sticky=tk.W, pady=(10, 0))
        
        # AIæ‘˜è¦èªªæ˜
        self.ai_summary_info = ttk.Label(
            options_frame,
            text="åˆ†æä¸»é¡Œé ˜åŸŸã€ç ”ç©¶æ–¹æ³•ã€è¦–è§’ã€çµè«–ç­‰",
            font=("Arial", 8),
            foreground="gray"
        )
        self.ai_summary_info.grid(row=3, column=0, sticky=tk.W, pady=(5, 0))
        
        # AI APIè¨­å®šå€åŸŸ
        api_frame = ttk.LabelFrame(left_frame, text="AI APIè¨­å®š", padding="10")
        api_frame.grid(row=5, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(api_frame, text="OpenAI API Key:").grid(row=0, column=0, sticky=tk.W)
        self.api_key_entry = ttk.Entry(api_frame, width=40, show="*")
        self.api_key_entry.grid(row=0, column=1, padx=(10, 0), sticky=(tk.W, tk.E))
        
        ttk.Button(api_frame, text="æ¸¬è©¦é€£æ¥", command=self.test_api_connection).grid(row=0, column=2, padx=(10, 0))
        
        self.api_status_label = ttk.Label(api_frame, text="æœªè¨­å®š", foreground="gray")
        self.api_status_label.grid(row=1, column=0, columnspan=3, pady=(5, 0), sticky=tk.W)
        
        # è½‰æ›æŒ‰éˆ•
        convert_button = ttk.Button(left_frame, text="é–‹å§‹è½‰æ›", command=self.convert_speech_to_text)
        convert_button.grid(row=6, column=0, columnspan=2, pady=(10, 0))
        
        # ==================== å³å´å€åŸŸ ====================
        
        # çµæœé¡¯ç¤ºå€åŸŸ
        result_frame = ttk.LabelFrame(right_frame, text="è½‰æ›çµæœ", padding="10")
        result_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        self.text_result = scrolledtext.ScrolledText(result_frame, width=50, height=20)
        self.text_result.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # AIæ‘˜è¦çµæœå€åŸŸ
        ai_result_frame = ttk.LabelFrame(right_frame, text="AIæ™ºèƒ½æ‘˜è¦", padding="10")
        ai_result_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        self.ai_result_text = scrolledtext.ScrolledText(ai_result_frame, width=50, height=12)
        self.ai_result_text.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # è‡ªå®šç¾©Promptå€åŸŸ
        prompt_frame = ttk.LabelFrame(ai_result_frame, text="è‡ªå®šç¾©åˆ†æ", padding="5")
        prompt_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(10, 0))
        
        ttk.Label(prompt_frame, text="è‡ªå®šç¾©æç¤ºè©:").grid(row=0, column=0, sticky=tk.W)
        
        self.custom_prompt_text = scrolledtext.ScrolledText(prompt_frame, width=50, height=3)
        self.custom_prompt_text.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(5, 10))
        
        # é è¨­æç¤ºè©æŒ‰éˆ•
        preset_frame = ttk.Frame(prompt_frame)
        preset_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Button(preset_frame, text="å­¸è¡“åˆ†æ", command=lambda: self.load_preset_prompt("academic")).grid(row=0, column=0, padx=(0, 5))
        ttk.Button(preset_frame, text="å•†æ¥­å ±å‘Š", command=lambda: self.load_preset_prompt("business")).grid(row=0, column=1, padx=(0, 5))
        ttk.Button(preset_frame, text="æœƒè­°ç´€éŒ„", command=lambda: self.load_preset_prompt("meeting")).grid(row=0, column=2, padx=(0, 5))
        ttk.Button(preset_frame, text="æ¸…ç©º", command=self.clear_custom_prompt).grid(row=0, column=3)
        
        # AIæ‘˜è¦æ§åˆ¶æŒ‰éˆ•
        ai_control_frame = ttk.Frame(ai_result_frame)
        ai_control_frame.grid(row=2, column=0, columnspan=2, pady=(10, 0))
        
        ttk.Button(ai_control_frame, text="æ¨™æº–AIæ‘˜è¦", command=self.generate_ai_summary).grid(row=0, column=0, padx=(0, 10))
        ttk.Button(ai_control_frame, text="è‡ªå®šç¾©åˆ†æ", command=self.generate_custom_analysis).grid(row=0, column=1, padx=(0, 10))
        ttk.Button(ai_control_frame, text="æ¸…ç©ºæ‘˜è¦", command=self.clear_ai_summary).grid(row=0, column=2)
        
        # å°å‡ºæŒ‰éˆ•
        export_frame = ttk.Frame(right_frame)
        export_frame.grid(row=2, column=0, columnspan=2, pady=(10, 0))
        
        ttk.Button(export_frame, text="å°å‡ºTXT", command=self.export_txt).grid(row=0, column=0, padx=(0, 10))
        ttk.Button(export_frame, text="å°å‡ºDOCX", command=self.export_docx).grid(row=0, column=1, padx=(0, 10))
        ttk.Button(export_frame, text="å°å‡ºå®Œæ•´å ±å‘Š", command=self.export_full_report).grid(row=0, column=2, padx=(0, 10))
        
        # é‡ç½®æŒ‰éˆ•
        reset_button = ttk.Button(export_frame, text="é‡ç½®ç³»çµ±", command=self.reset_program, style="Reset.TButton")
        reset_button.grid(row=0, column=3)
        
        # é…ç½®æ¨£å¼
        style = ttk.Style()
        style.configure("Reset.TButton", foreground="red")
        
        # é…ç½®æ¬Šé‡ - é€™æ˜¯é—œéµæ”¹å–„ï¼
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        
        main_frame.columnconfigure(0, weight=1)  # å·¦æ¬„
        main_frame.columnconfigure(1, weight=0)  # å·¦æ¬„å»¶ä¼¸
        main_frame.columnconfigure(2, weight=1)  # å³æ¬„
        main_frame.columnconfigure(3, weight=0)  # å³æ¬„å»¶ä¼¸
        main_frame.rowconfigure(1, weight=1)
        
        # å·¦å´æ¬Šé‡é…ç½®
        left_frame.columnconfigure(0, weight=1)
        left_frame.columnconfigure(1, weight=0)
        left_frame.rowconfigure(1, weight=1)  # æª”æ¡ˆç®¡ç†å€åŸŸå¯æ“´å±•
        
        # å³å´æ¬Šé‡é…ç½®
        right_frame.columnconfigure(0, weight=1)
        right_frame.columnconfigure(1, weight=0)
        right_frame.rowconfigure(0, weight=2)  # è½‰æ›çµæœå€åŸŸ
        right_frame.rowconfigure(1, weight=1)  # AIæ‘˜è¦å€åŸŸ
        
        # å„å€åŸŸå…§éƒ¨æ¬Šé‡é…ç½®
        record_frame.columnconfigure(0, weight=1)
        upload_frame.columnconfigure(0, weight=1)
        list_frame.columnconfigure(0, weight=1)
        list_frame.rowconfigure(0, weight=1)
        result_frame.columnconfigure(0, weight=1)
        result_frame.rowconfigure(0, weight=1)
        ai_result_frame.columnconfigure(0, weight=1)
        ai_result_frame.rowconfigure(0, weight=1)
        api_frame.columnconfigure(1, weight=1)
        
        # è‡ªå®šç¾©promptå€åŸŸæ¬Šé‡é…ç½®
        prompt_frame.columnconfigure(0, weight=1)
        prompt_frame.rowconfigure(1, weight=1)
    
    def start_recording(self):
        """é–‹å§‹éŒ„éŸ³"""
        if self.is_recording:
            return
            
        self.is_recording = True
        self.is_paused = False
        self.recording_segments = []
        self.recording_start_time = time.time()
        self.total_pause_time = 0
        
        # æ›´æ–°æŒ‰éˆ•ç‹€æ…‹
        self.record_button.config(state="disabled")
        self.pause_button.config(state="normal")
        self.resume_button.config(state="disabled")
        self.stop_button.config(state="normal")
        self.record_status.config(text="æ­£åœ¨éŒ„éŸ³...")
        
        # åœ¨æ–°ç·šç¨‹ä¸­éŒ„éŸ³
        self.recording_thread = threading.Thread(target=self.record_audio, daemon=True)
        self.recording_thread.start()
    
    def pause_recording(self):
        """æš«åœéŒ„éŸ³"""
        if not self.is_recording or self.is_paused:
            return
            
        self.is_paused = True
        self.pause_start_time = time.time()
        
        # æ›´æ–°æŒ‰éˆ•ç‹€æ…‹
        self.pause_button.config(state="disabled")
        self.resume_button.config(state="normal")
        self.record_status.config(text="éŒ„éŸ³å·²æš«åœ")
        
        print("éŒ„éŸ³å·²æš«åœ")
    
    def resume_recording(self):
        """ç¹¼çºŒéŒ„éŸ³"""
        if not self.is_recording or not self.is_paused:
            return
            
        # è¨ˆç®—æš«åœæ™‚é–“
        if self.pause_start_time:
            self.total_pause_time += time.time() - self.pause_start_time
            self.pause_start_time = None
        
        self.is_paused = False
        
        # æ›´æ–°æŒ‰éˆ•ç‹€æ…‹
        self.pause_button.config(state="normal")
        self.resume_button.config(state="disabled")
        self.record_status.config(text="æ­£åœ¨éŒ„éŸ³...")
        
        print("éŒ„éŸ³å·²ç¹¼çºŒ")
    
    def stop_recording(self):
        """çµæŸéŒ„éŸ³"""
        if not self.is_recording:
            return
            
        # å¦‚æœæ­£åœ¨æš«åœï¼Œå…ˆè¨ˆç®—æš«åœæ™‚é–“
        if self.is_paused and self.pause_start_time:
            self.total_pause_time += time.time() - self.pause_start_time
            self.pause_start_time = None
        
        self.is_recording = False
        self.is_paused = False
        
        # æ›´æ–°æŒ‰éˆ•ç‹€æ…‹
        self.record_button.config(state="normal")
        self.pause_button.config(state="disabled")
        self.resume_button.config(state="disabled")
        self.stop_button.config(state="disabled")
        
        # ç­‰å¾…éŒ„éŸ³ç·šç¨‹çµæŸ
        if self.recording_thread and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=2)
        
        # è¨ˆç®—å¯¦éš›éŒ„éŸ³æ™‚é–“ï¼ˆæ‰£é™¤æš«åœæ™‚é–“ï¼‰
        if self.recording_start_time:
            total_time = time.time() - self.recording_start_time
            actual_recording_time = total_time - self.total_pause_time
            self.record_status.config(text=f"éŒ„éŸ³å·²çµæŸ (å¯¦éš›éŒ„éŸ³: {actual_recording_time:.1f}ç§’)")
        else:
            self.record_status.config(text="éŒ„éŸ³å·²çµæŸ")
        
        print("éŒ„éŸ³å·²çµæŸ")
    
    def record_audio(self):
        """éŒ„éŸ³å‡½æ•¸"""
        try:
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1)
            
            if self.record_mode_var.get() == "continuous":
                # é€£çºŒéŒ„éŸ³æ¨¡å¼
                self.continuous_recording()
            else:
                # å–®å¥éŒ„éŸ³æ¨¡å¼
                self.single_recording()
                
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"éŒ„éŸ³å¤±æ•—: {e}"))
            self.root.after(0, self.stop_recording)
    
    def reset_program(self):
        """é‡ç½®ç¨‹å¼çš„æ–¹æ³•ï¼Œå¯åœ¨UIä¸­èª¿ç”¨"""
        try:
            success = self.reset_all()
            if success:
                messagebox.showinfo("é‡ç½®", "ç³»çµ±å·²æˆåŠŸé‡ç½®")
            else:
                messagebox.showwarning("é‡ç½®", "é‡ç½®éç¨‹ä¸­é‡åˆ°ä¸€äº›å•é¡Œï¼Œè«‹æª¢æŸ¥çµ‚ç«¯è¼¸å‡º")
        except Exception as e:
            print(f"é‡ç½®ç¨‹å¼å¤±æ•—: {e}")
            messagebox.showerror("éŒ¯èª¤", f"é‡ç½®å¤±æ•—: {e}")
    
    def toggle_timestamp_option(self):
        """åˆ‡æ›æ™‚é–“æˆ³é¸é …"""
        self.enable_timestamps = self.timestamp_var.get()
        if self.enable_timestamps:
            print("å·²å•Ÿç”¨æ™‚é–“æˆ³åŠŸèƒ½")
        else:
            print("å·²é—œé–‰æ™‚é–“æˆ³åŠŸèƒ½")
    
    def toggle_ai_summary_option(self):
        """åˆ‡æ›AIæ‘˜è¦é¸é …"""
        self.enable_ai_summary = self.ai_summary_var.get()
        if self.enable_ai_summary:
            print("å·²å•Ÿç”¨AIæ‘˜è¦åŠŸèƒ½")
            if not self.openai_api_key:
                messagebox.showinfo("æç¤º", "è«‹è¨­å®šOpenAI API Keyä»¥ä½¿ç”¨AIæ‘˜è¦åŠŸèƒ½")
        else:
            print("å·²é—œé–‰AIæ‘˜è¦åŠŸèƒ½")
    
    def test_api_connection(self):
        """æ¸¬è©¦OpenAI APIé€£æ¥"""
        api_key = self.api_key_entry.get().strip()
        if not api_key:
            messagebox.showwarning("è­¦å‘Š", "è«‹è¼¸å…¥OpenAI API Key")
            return
        
        try:
            # è¨­å®šAPI key
            self.openai_api_key = api_key
            
            # æ¸¬è©¦é€£æ¥ - å˜—è©¦å°å…¥ä¸¦æ¸¬è©¦OpenAI
            try:
                import openai
                
                # æª¢æŸ¥ç‰ˆæœ¬ä¸¦é¸æ“‡é©ç•¶çš„APIèª¿ç”¨æ–¹å¼
                if hasattr(openai, '__version__') and openai.__version__.startswith('1.'):
                    # OpenAI v1.x
                    client = openai.OpenAI(api_key=api_key)
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": "Hello"}],
                        max_tokens=5
                    )
                else:
                    # OpenAI v0.x (èˆŠç‰ˆ)
                    openai.api_key = api_key
                    response = openai.ChatCompletion.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": "Hello"}],
                        max_tokens=5
                    )
                
                self.api_status_label.config(text="APIé€£æ¥æˆåŠŸ", foreground="green")
                messagebox.showinfo("æˆåŠŸ", "OpenAI APIé€£æ¥æ¸¬è©¦æˆåŠŸï¼")
                
            except ImportError:
                self.api_status_label.config(text="ç¼ºå°‘openaiå¥—ä»¶", foreground="red")
                result = messagebox.askyesno("ç¼ºå°‘å¥—ä»¶", "ç¼ºå°‘openaiå¥—ä»¶ï¼Œæ˜¯å¦è¦è‡ªå‹•å®‰è£ï¼Ÿ")
                if result:
                    self.install_openai_package()
            
        except Exception as e:
            self.api_status_label.config(text="APIé€£æ¥å¤±æ•—", foreground="red")
            messagebox.showerror("éŒ¯èª¤", f"APIé€£æ¥å¤±æ•—ï¼š{str(e)}")
    
    def install_openai_package(self):
        """è‡ªå‹•å®‰è£OpenAIå¥—ä»¶"""
        try:
            import subprocess
            import sys
            
            # åœ¨æ–°ç·šç¨‹ä¸­å®‰è£å¥—ä»¶
            def install_in_thread():
                try:
                    subprocess.run([sys.executable, "-m", "pip", "install", "openai"], 
                                 check=True, capture_output=True, text=True)
                    self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", "OpenAIå¥—ä»¶å®‰è£æˆåŠŸï¼è«‹é‡æ–°æ¸¬è©¦APIé€£æ¥ã€‚"))
                    self.root.after(0, lambda: self.api_status_label.config(text="å¥—ä»¶å®‰è£å®Œæˆ", foreground="blue"))
                except Exception as e:
                    self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"å®‰è£å¤±æ•—ï¼š{str(e)}"))
                    self.root.after(0, lambda: self.api_status_label.config(text="å®‰è£å¤±æ•—", foreground="red"))
            
            threading.Thread(target=install_in_thread, daemon=True).start()
            self.api_status_label.config(text="æ­£åœ¨å®‰è£å¥—ä»¶...", foreground="blue")
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"å®‰è£éç¨‹ä¸­å‡ºç¾éŒ¯èª¤ï¼š{str(e)}")
    
    def generate_ai_summary(self):
        """ç”ŸæˆAIæ‘˜è¦"""
        if not self.enable_ai_summary:
            messagebox.showinfo("æç¤º", "è«‹å…ˆå•Ÿç”¨AIæ‘˜è¦åŠŸèƒ½")
            return
        
        if not self.openai_api_key:
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆè¨­å®šä¸¦æ¸¬è©¦OpenAI API Key")
            return
        
        # å–å¾—è½‰æ›çµæœæ–‡å­—
        content = self.text_result.get(1.0, tk.END).strip()
        if not content:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰è½‰æ›çµæœå¯ä»¥åˆ†æ")
            return
        
        # åœ¨æ–°ç·šç¨‹ä¸­åŸ·è¡ŒAIåˆ†æ
        threading.Thread(target=self.perform_ai_analysis, args=(content,), daemon=True).start()
        
        # æ›´æ–°ç‹€æ…‹
        self.ai_result_text.delete(1.0, tk.END)
        self.ai_result_text.insert(tk.END, "æ­£åœ¨é€²è¡ŒAIåˆ†æï¼Œè«‹ç¨å€™...\n")
    
    def perform_ai_analysis(self, content):
        """åŸ·è¡ŒAIåˆ†æ"""
        try:
            import openai
            
            # æ§‹å»ºæç¤ºè©
            prompt = self.build_analysis_prompt(content)
            
            # æª¢æŸ¥OpenAIç‰ˆæœ¬ä¸¦é¸æ“‡é©ç•¶çš„APIèª¿ç”¨æ–¹å¼
            if hasattr(openai, '__version__') and openai.__version__.startswith('1.'):
                # OpenAI v1.x
                client = openai.OpenAI(api_key=self.openai_api_key)
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å…§å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•·åˆ†ææ¼”è¬›ã€è¬›åº§å’Œæœƒè­°å…§å®¹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.3
                )
                analysis_result = response.choices[0].message.content
            else:
                # OpenAI v0.x (èˆŠç‰ˆ)
                openai.api_key = self.openai_api_key
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å…§å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•·åˆ†ææ¼”è¬›ã€è¬›åº§å’Œæœƒè­°å…§å®¹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.3
                )
                analysis_result = response.choices[0].message.content
            
            # å„²å­˜åˆ†æçµæœ
            self.ai_summary_result = analysis_result
            
            # æ›´æ–°UI
            self.root.after(0, self.update_ai_result, analysis_result)
            
        except Exception as e:
            error_message = f"AIåˆ†æå¤±æ•—ï¼š{str(e)}"
            print(error_message)
            self.root.after(0, self.update_ai_result, error_message)
    
    def build_analysis_prompt(self, content):
        """æ§‹å»ºAIåˆ†ææç¤ºè©"""
        prompt = f"""
è«‹åˆ†æä»¥ä¸‹æ¼”è¬›/è¬›åº§å…§å®¹ï¼Œä¸¦æä¾›çµæ§‹åŒ–çš„æ‘˜è¦åˆ†æï¼š

ã€åŸå§‹å…§å®¹ã€‘
{content}

ã€åˆ†æè¦æ±‚ã€‘
è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æä¾›è©³ç´°åˆ†æï¼š

## ğŸ“‹ å…§å®¹æ¦‚è¦½
- å…§å®¹é¡å‹ï¼š[è¬›åº§/æ¼”è¬›/æœƒè­°/è¨è«–ç­‰]
- ä¼°è¨ˆæ™‚é•·ï¼š[æ ¹æ“šå…§å®¹é•·åº¦ä¼°è¨ˆ]
- èªè¨€é¢¨æ ¼ï¼š[æ­£å¼/éæ­£å¼/å­¸è¡“/å•†æ¥­ç­‰]

## ğŸ¯ ä¸»é¡Œé ˜åŸŸ
- ä¸»è¦é ˜åŸŸï¼š
- æ¬¡è¦é ˜åŸŸï¼š
- é—œéµè­°é¡Œï¼š

## ğŸ”¬ ç ”ç©¶æ–¹æ³•
- ç ”ç©¶å–å‘ï¼š[ç†è«–/å¯¦å‹™/æ··åˆ]
- åˆ†ææ–¹å¼ï¼š[å®šæ€§/å®šé‡/æ¡ˆä¾‹ç ”ç©¶ç­‰]
- è«–è­‰æ–¹å¼ï¼š[æ­¸ç´/æ¼”ç¹¹/æ¯”è¼ƒåˆ†æç­‰]

## ğŸ‘ï¸ ç ”ç©¶è¦–è§’
- å­¸è¡“è§€é»ï¼š
- å¯¦å‹™è§’åº¦ï¼š
- æ‰¹åˆ¤æ€ç¶­ï¼š

## ğŸ’¡ æ ¸å¿ƒçµè«–
- ä¸»è¦ç™¼ç¾ï¼š
- é‡è¦è§€é»ï¼š
- å»ºè­°è¡Œå‹•ï¼š

## ğŸ”— é—œéµæ¦‚å¿µ
- é‡è¦è¡“èªï¼š
- æ ¸å¿ƒç†è«–ï¼š
- å¼•ç”¨ä¾†æºï¼š

## ğŸ“Š å…§å®¹çµæ§‹
- é–‹å ´æ–¹å¼ï¼š
- è«–è¿°é‚è¼¯ï¼š
- çµå°¾ç¸½çµï¼š

## ğŸ’­ è£œå……èªªæ˜
- ç‰¹è‰²äº®é»ï¼š
- å¯èƒ½ç–‘å•ï¼š
- å»¶ä¼¸æ€è€ƒï¼š

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒå°ˆæ¥­ä¸”æ˜“æ‡‚çš„èªè¨€é¢¨æ ¼ã€‚
"""
        return prompt
    
    def update_ai_result(self, result):
        """æ›´æ–°AIåˆ†æçµæœé¡¯ç¤º"""
        self.ai_result_text.delete(1.0, tk.END)
        self.ai_result_text.insert(tk.END, result)
    
    def clear_ai_summary(self):
        """æ¸…ç©ºAIæ‘˜è¦"""
        self.ai_result_text.delete(1.0, tk.END)
        self.ai_summary_result = ""
    
    def load_preset_prompt(self, preset_type):
        """è¼‰å…¥é è¨­æç¤ºè©"""
        presets = {
            "academic": """è«‹ä»¥å­¸è¡“ç ”ç©¶çš„è§’åº¦åˆ†æé€™æ®µæ–‡æœ¬ï¼Œé‡é»é—œæ³¨ï¼š
1. ç ”ç©¶ä¸»é¡Œå’Œå•é¡Œ
2. ç†è«–æ¡†æ¶å’Œæ–¹æ³•è«–
3. ä¸»è¦ç™¼ç¾å’Œè«–è­‰
4. å­¸è¡“è²¢ç»å’Œæ„ç¾©
5. å¯èƒ½çš„ç ”ç©¶é™åˆ¶
è«‹æä¾›è©³ç´°çš„å­¸è¡“åˆ†æå ±å‘Šã€‚""",
            
            "business": """è«‹ä»¥å•†æ¥­åˆ†æçš„è§’åº¦è§£è®€é€™æ®µå…§å®¹ï¼ŒåŒ…å«ï¼š
1. æ ¸å¿ƒå•†æ¥­è­°é¡Œ
2. å¸‚å ´æ©Ÿæœƒå’ŒæŒ‘æˆ°
3. ç­–ç•¥å»ºè­°å’Œè¡Œå‹•æ–¹æ¡ˆ
4. é¢¨éšªè©•ä¼°
5. é æœŸæ•ˆç›Šå’Œå½±éŸ¿
è«‹æä¾›å¯¦ç”¨çš„å•†æ¥­æ´å¯Ÿã€‚""",
            
            "meeting": """è«‹æ•´ç†é€™æ®µæœƒè­°å…§å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. æœƒè­°é‡é»è­°é¡Œ
2. ä¸»è¦è¨è«–å…§å®¹
3. æ±ºè­°äº‹é …å’Œè¡Œå‹•è¨ˆç•«
4. è²¬ä»»åˆ†å·¥
5. å¾ŒçºŒè¿½è¹¤äº‹é …
è«‹æä¾›çµæ§‹åŒ–çš„æœƒè­°ç´€éŒ„ã€‚"""
        }
        
        if preset_type in presets:
            self.custom_prompt_text.delete(1.0, tk.END)
            self.custom_prompt_text.insert(1.0, presets[preset_type])
    
    def clear_custom_prompt(self):
        """æ¸…ç©ºè‡ªå®šç¾©æç¤ºè©"""
        self.custom_prompt_text.delete(1.0, tk.END)
    
    def generate_custom_analysis(self):
        """ä½¿ç”¨è‡ªå®šç¾©æç¤ºè©ç”ŸæˆAIåˆ†æ"""
        content = self.text_result.get(1.0, tk.END).strip()
        custom_prompt = self.custom_prompt_text.get(1.0, tk.END).strip()
        
        if not content:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰è½‰æ›çµæœå¯ä»¥åˆ†æ")
            return
        
        if not custom_prompt:
            messagebox.showwarning("è­¦å‘Š", "è«‹è¼¸å…¥è‡ªå®šç¾©æç¤ºè©")
            return
        
        if not self.api_key_entry.get().strip():
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆè¨­å®šOpenAI API Key")
            return
        
        # åœ¨æ–°ç·šç¨‹ä¸­åŸ·è¡Œåˆ†æ
        threading.Thread(target=self._perform_custom_analysis, args=(content, custom_prompt), daemon=True).start()
        
        # é¡¯ç¤ºåˆ†æä¸­ç‹€æ…‹
        self.ai_result_text.delete(1.0, tk.END)
        self.ai_result_text.insert(tk.END, "ğŸ¤– æ­£åœ¨ä½¿ç”¨è‡ªå®šç¾©æç¤ºè©é€²è¡ŒAIåˆ†æ...\n\n")
        self.ai_result_text.update()
    
    def _perform_custom_analysis(self, content, custom_prompt):
        """åŸ·è¡Œè‡ªå®šç¾©AIåˆ†æ"""
        try:
            api_key = self.api_key_entry.get().strip()
            
            # æª¢æŸ¥ OpenAI ç‰ˆæœ¬ä¸¦ä½¿ç”¨ç›¸æ‡‰çš„ API
            try:
                import openai
                if hasattr(openai, '__version__') and openai.__version__.startswith('0.'):
                    # èˆŠç‰ˆæœ¬ API (0.x)
                    openai.api_key = api_key
                    
                    response = openai.ChatCompletion.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œè«‹æ ¹æ“šç”¨æˆ¶çš„è¦æ±‚é€²è¡Œæ·±åº¦åˆ†æã€‚"},
                            {"role": "user", "content": f"{custom_prompt}\n\nä»¥ä¸‹æ˜¯è¦åˆ†æçš„æ–‡æœ¬å…§å®¹ï¼š\n\n{content}"}
                        ],
                        max_tokens=2000,
                        temperature=0.7
                    )
                    
                    analysis_result = response.choices[0].message.content
                    
                else:
                    # æ–°ç‰ˆæœ¬ API (1.x)
                    from openai import OpenAI
                    client = OpenAI(api_key=api_key)
                    
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œè«‹æ ¹æ“šç”¨æˆ¶çš„è¦æ±‚é€²è¡Œæ·±åº¦åˆ†æã€‚"},
                            {"role": "user", "content": f"{custom_prompt}\n\nä»¥ä¸‹æ˜¯è¦åˆ†æçš„æ–‡æœ¬å…§å®¹ï¼š\n\n{content}"}
                        ],
                        max_tokens=2000,
                        temperature=0.7
                    )
                    
                    analysis_result = response.choices[0].message.content
                
                # åœ¨ä¸»ç·šç¨‹ä¸­æ›´æ–°UI
                self.root.after(0, lambda: self.update_custom_analysis_result(analysis_result))
                
            except Exception as api_error:
                error_msg = f"API èª¿ç”¨å¤±æ•—: {str(api_error)}"
                self.root.after(0, lambda: self.update_custom_analysis_result(f"âŒ {error_msg}"))
                
        except Exception as e:
            error_msg = f"è‡ªå®šç¾©åˆ†æå¤±æ•—: {str(e)}"
            self.root.after(0, lambda: self.update_custom_analysis_result(f"âŒ {error_msg}"))
    
    def update_custom_analysis_result(self, result):
        """æ›´æ–°è‡ªå®šç¾©åˆ†æçµæœ"""
        self.ai_result_text.delete(1.0, tk.END)
        self.ai_result_text.insert(tk.END, "ğŸ¯ è‡ªå®šç¾©AIåˆ†æçµæœ\n")
        self.ai_result_text.insert(tk.END, "=" * 50 + "\n\n")
        self.ai_result_text.insert(tk.END, result)
    
    def export_full_report(self):
        """å°å‡ºå®Œæ•´å ±å‘Šï¼ˆåŒ…å«åŸæ–‡å’ŒAIæ‘˜è¦ï¼‰"""
        content = self.text_result.get(1.0, tk.END).strip()
        ai_summary = self.ai_result_text.get(1.0, tk.END).strip()
        
        if not content:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰è½‰æ›çµæœå¯ä»¥å°å‡º")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="å„²å­˜å®Œæ•´å ±å‘Š",
            defaultextension=".docx",
            filetypes=[("Wordæª”æ¡ˆ", "*.docx"), ("æ–‡å­—æª”æ¡ˆ", "*.txt"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")]
        )
        
        if file_path:
            try:
                if file_path.endswith('.docx'):
                    self.export_full_docx_report(file_path, content, ai_summary)
                else:
                    self.export_full_txt_report(file_path, content, ai_summary)
                messagebox.showinfo("æˆåŠŸ", f"å®Œæ•´å ±å‘Šå·²å°å‡ºè‡³: {file_path}")
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"å°å‡ºå¤±æ•—: {e}")
    
    def export_full_docx_report(self, file_path, content, ai_summary):
        """å°å‡ºå®Œæ•´DOCXå ±å‘Š"""
        doc = Document()
        
        # æ¨™é¡Œ
        doc.add_heading('èªéŸ³è½‰æ–‡å­—å®Œæ•´åˆ†æå ±å‘Š', 0)
        doc.add_paragraph(f'ç”Ÿæˆæ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        doc.add_paragraph('-' * 80)
        
        # åŸå§‹è½‰æ›çµæœ
        doc.add_heading('ğŸ“ èªéŸ³è½‰æ–‡å­—çµæœ', 1)
        doc.add_paragraph(content)
        
        # AIæ‘˜è¦çµæœ
        if ai_summary:
            doc.add_heading('ğŸ¤– AIæ™ºèƒ½æ‘˜è¦åˆ†æ', 1)
            doc.add_paragraph(ai_summary)
        else:
            doc.add_heading('ğŸ¤– AIæ™ºèƒ½æ‘˜è¦åˆ†æ', 1)
            doc.add_paragraph('å°šæœªé€²è¡ŒAIåˆ†æ')
        
        doc.save(file_path)
    
    def export_full_txt_report(self, file_path, content, ai_summary):
        """å°å‡ºå®Œæ•´TXTå ±å‘Š"""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("èªéŸ³è½‰æ–‡å­—å®Œæ•´åˆ†æå ±å‘Š\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("ğŸ“ èªéŸ³è½‰æ–‡å­—çµæœ\n")
            f.write("-" * 40 + "\n")
            f.write(content + "\n\n")
            
            f.write("ğŸ¤– AIæ™ºèƒ½æ‘˜è¦åˆ†æ\n")
            f.write("-" * 40 + "\n")
            if ai_summary:
                f.write(ai_summary + "\n")
            else:
                f.write("å°šæœªé€²è¡ŒAIåˆ†æ\n")
    
    def format_timestamp(self, seconds):
        """æ ¼å¼åŒ–æ™‚é–“æˆ³"""
        total_seconds = int(seconds)
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        secs = total_seconds % 60
        
        if hours > 0:
            return f"[{hours:02d}:{minutes:02d}:{secs:02d}]"
        else:
            return f"[{minutes:02d}:{secs:02d}]"
    
    def get_audio_duration(self, file_path):
        """å–å¾—éŸ³æª”é•·åº¦ï¼ˆç§’ï¼‰"""
        try:
            audio = AudioSegment.from_file(file_path)
            return len(audio) / 1000.0  # è½‰æ›ç‚ºç§’
        except Exception as e:
            print(f"ç„¡æ³•å–å¾—éŸ³æª”é•·åº¦ {file_path}: {e}")
            return 0
    
    def add_timestamps_to_text(self, text, start_time):
        """ç‚ºæ–‡å­—æ·»åŠ æ™‚é–“æˆ³"""
        if not text or not self.enable_timestamps:
            return text
        
        # å°‡æ–‡å­—åˆ†å‰²æˆå¥å­
        sentences = self.split_into_sentences(text)
        if not sentences:
            return text
        
        # ä¼°ç®—æ¯å€‹å¥å­çš„æ™‚é–“é–“éš”
        total_duration = self.get_estimated_speech_duration(text)
        if total_duration <= 0:
            total_duration = 60  # é è¨­ä¼°è¨ˆæ™‚é–“
        
        time_per_sentence = total_duration / len(sentences)
        
        # ç‚ºæ¯å€‹å¥å­æ·»åŠ æ™‚é–“æˆ³
        timestamped_sentences = []
        current_time = start_time
        
        for sentence in sentences:
            if sentence.strip():  # åªè™•ç†éç©ºå¥å­
                timestamp = self.format_timestamp(current_time)
                timestamped_sentences.append(f"{timestamp} {sentence.strip()}")
                current_time += time_per_sentence
        
        return "\n".join(timestamped_sentences)
    
    def split_into_sentences(self, text):
        """å°‡æ–‡å­—åˆ†å‰²æˆå¥å­"""
        import re
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åˆ†å‰²å¥å­ï¼ˆæ”¯æ´ä¸­è‹±æ–‡ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›.!?;]\s*', text)
        # éæ¿¾ç©ºå¥å­
        return [s.strip() for s in sentences if s.strip()]
    
    def get_estimated_speech_duration(self, text):
        """ä¼°ç®—èªéŸ³æŒçºŒæ™‚é–“ï¼ˆåŸºæ–¼æ–‡å­—é•·åº¦ï¼‰"""
        # ä¸­æ–‡å­—ç¬¦æ•¸ + è‹±æ–‡å–®è©æ•¸
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        english_words = len([w for w in text.split() if w.isalpha()])
        
        # ä¼°ç®—ï¼šä¸­æ–‡ç´„æ¯åˆ†é˜200å­—ï¼Œè‹±æ–‡ç´„æ¯åˆ†é˜150è©
        chinese_duration = chinese_chars / 200 * 60  # ç§’
        english_duration = english_words / 150 * 60  # ç§’
        
        return max(chinese_duration + english_duration, 10)  # æœ€å°‘10ç§’
    
    def get_whisper_timestamps(self, audio_data, start_time=0):
        """ä½¿ç”¨Whisperå–å¾—ç²¾ç¢ºçš„æ™‚é–“æˆ³"""
        try:
            if not self.whisper_model:
                raise Exception("Whisperæ¨¡å‹æœªè¼‰å…¥")
            
            # å°‡AudioDataè½‰æ›ç‚ºè‡¨æ™‚æª”æ¡ˆ
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            temp_file_path = temp_file.name
            self.temp_files.append(temp_file_path)
            
            try:
                with open(temp_file_path, "wb") as f:
                    f.write(audio_data.get_wav_data())
                
                # ä½¿ç”¨Whisperè½‰æ›ä¸¦å–å¾—segmentè³‡è¨Š
                language = self.language_var.get()
                if language == "auto":
                    result = self.whisper_model.transcribe(temp_file_path, word_timestamps=True)
                else:
                    lang_code = "zh" if language == "zh-TW" else "en"
                    result = self.whisper_model.transcribe(temp_file_path, language=lang_code, word_timestamps=True)
                
                # è™•ç†segmentsä¸¦æ·»åŠ èµ·å§‹æ™‚é–“åç§»
                timestamped_text = []
                for segment in result.get("segments", []):
                    segment_start = start_time + segment["start"]
                    timestamp = self.format_timestamp(segment_start)
                    text = segment["text"].strip()
                    if text:
                        timestamped_text.append(f"{timestamp} {text}")
                
                return "\n".join(timestamped_text)
                
            finally:
                # è‡¨æ™‚æª”æ¡ˆæœƒåœ¨ç¨‹å¼çµæŸæˆ–é‡ç½®æ™‚çµ±ä¸€æ¸…ç†
                pass
                
        except Exception as e:
            print(f"Whisperæ™‚é–“æˆ³è½‰æ›å¤±æ•—: {e}")
            # å¦‚æœWhisperå¤±æ•—ï¼Œå›é€€åˆ°ä¼°ç®—æ–¹æ³•
            text = self.perform_recognition(audio_data)
            return self.add_timestamps_to_text(text, start_time)
    
    def load_audio_file_for_whisper(self, file_path):
        """ç‚ºWhisperè¼‰å…¥éŸ³æª”ä¸¦è½‰æ›ç‚ºAudioDataæ ¼å¼"""
        try:
            # æª¢æŸ¥æª”æ¡ˆæ ¼å¼ä¸¦è½‰æ›
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext in ['.mp3', '.mp4', '.m4a', '.flac', '.aac', '.ogg']:
                # ä½¿ç”¨pydubè½‰æ›ç‚ºWAVæ ¼å¼
                audio = AudioSegment.from_file(file_path)
                
                # å‰µå»ºè‡¨æ™‚WAVæª”æ¡ˆ
                temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                temp_wav_path = temp_wav.name
                self.temp_files.append(temp_wav_path)
                audio.export(temp_wav_path, format="wav")
                
                # è¼‰å…¥è½‰æ›å¾Œçš„æª”æ¡ˆ
                with sr.AudioFile(temp_wav_path) as source:
                    return self.recognizer.record(source)
            else:
                # ç›´æ¥è¼‰å…¥WAVæª”æ¡ˆ
                with sr.AudioFile(file_path) as source:
                    return self.recognizer.record(source)
                    
        except Exception as e:
            print(f"è¼‰å…¥éŸ³æª”å¤±æ•— {file_path}: {e}")
            return None
    
    def add_audio_files(self):
        """æ–°å¢å¤šå€‹éŸ³è¨Šæª”æ¡ˆ"""
        file_paths = filedialog.askopenfilenames(
            title="é¸æ“‡éŸ³è¨Šæª”æ¡ˆ",
            filetypes=[
                ("éŸ³è¨Šæª”æ¡ˆ", "*.wav *.mp3 *.mp4 *.m4a *.flac *.aac *.ogg"),
                ("WAVæª”æ¡ˆ", "*.wav"),
                ("MP3æª”æ¡ˆ", "*.mp3"),
                ("MP4æª”æ¡ˆ", "*.mp4"),
                ("æ‰€æœ‰æª”æ¡ˆ", "*.*")
            ]
        )
        
        if file_paths:
            # æ–°å¢æª”æ¡ˆåˆ°åˆ—è¡¨
            for file_path in file_paths:
                file_info = {
                    'path': file_path,
                    'name': os.path.basename(file_path),
                    'order': len(self.audio_files) + 1
                }
                self.audio_files.append(file_info)
            
            # æ›´æ–°é¡¯ç¤º
            self.update_file_list()
            messagebox.showinfo("æˆåŠŸ", f"å·²æ–°å¢ {len(file_paths)} å€‹éŸ³è¨Šæª”æ¡ˆ")
    
    def clear_audio_files(self):
        """æ¸…ç©ºéŸ³è¨Šæª”æ¡ˆåˆ—è¡¨"""
        self.audio_files = []
        self.current_processing_index = 0
        self.update_file_list()
    
    def update_file_list(self):
        """æ›´æ–°æª”æ¡ˆåˆ—è¡¨é¡¯ç¤º"""
        # æ¸…ç©ºç¾æœ‰é …ç›®
        for item in self.file_tree.get_children():
            self.file_tree.delete(item)
        
        # æ–°å¢æª”æ¡ˆé …ç›®
        for i, file_info in enumerate(self.audio_files):
            self.file_tree.insert('', 'end', values=(
                file_info['order'],
                file_info['name'],
                file_info['path']
            ))
    
    def get_selected_item(self):
        """å–å¾—é¸ä¸­çš„é …ç›®ç´¢å¼•"""
        selection = self.file_tree.selection()
        if not selection:
            return None
        
        item = selection[0]
        values = self.file_tree.item(item, 'values')
        if not values:
            return None
        
        # æ‰¾åˆ°å°æ‡‰çš„æª”æ¡ˆç´¢å¼•
        for i, file_info in enumerate(self.audio_files):
            if file_info['name'] == values[1] and file_info['path'] == values[2]:
                return i
        return None
    
    def move_up(self):
        """ä¸Šç§»é¸ä¸­æª”æ¡ˆ"""
        index = self.get_selected_item()
        if index is None or index == 0:
            return
        
        # äº¤æ›ä½ç½®
        self.audio_files[index], self.audio_files[index-1] = \
            self.audio_files[index-1], self.audio_files[index]
        
        # æ›´æ–°é †åºè™Ÿ
        self.update_order_numbers()
        self.update_file_list()
        
        # ä¿æŒé¸ä¸­ç‹€æ…‹
        self.select_item_by_index(index-1)
    
    def move_down(self):
        """ä¸‹ç§»é¸ä¸­æª”æ¡ˆ"""
        index = self.get_selected_item()
        if index is None or index == len(self.audio_files) - 1:
            return
        
        # äº¤æ›ä½ç½®
        self.audio_files[index], self.audio_files[index+1] = \
            self.audio_files[index+1], self.audio_files[index]
        
        # æ›´æ–°é †åºè™Ÿ
        self.update_order_numbers()
        self.update_file_list()
        
        # ä¿æŒé¸ä¸­ç‹€æ…‹
        self.select_item_by_index(index+1)
    
    def remove_selected(self):
        """ç§»é™¤é¸ä¸­æª”æ¡ˆ"""
        index = self.get_selected_item()
        if index is None:
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆé¸æ“‡è¦ç§»é™¤çš„æª”æ¡ˆ")
            return
        
        # ç¢ºèªç§»é™¤
        file_name = self.audio_files[index]['name']
        if messagebox.askyesno("ç¢ºèª", f"ç¢ºå®šè¦ç§»é™¤æª”æ¡ˆ '{file_name}' å—ï¼Ÿ"):
            del self.audio_files[index]
            self.update_order_numbers()
            self.update_file_list()
    
    def update_order_numbers(self):
        """æ›´æ–°é †åºè™Ÿ"""
        for i, file_info in enumerate(self.audio_files):
            file_info['order'] = i + 1
    
    def select_item_by_index(self, index):
        """æ ¹æ“šç´¢å¼•é¸ä¸­é …ç›®"""
        if 0 <= index < len(self.audio_files):
            items = self.file_tree.get_children()
            if index < len(items):
                self.file_tree.selection_set(items[index])
                self.file_tree.focus(items[index])
    
    def batch_convert_files(self):
        """æ‰¹æ¬¡è½‰æ›æ‰€æœ‰æª”æ¡ˆ"""
        if not self.audio_files:
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆæ–°å¢éŸ³è¨Šæª”æ¡ˆ")
            return
        
        # åœ¨æ–°ç·šç¨‹ä¸­è™•ç†æ‰¹æ¬¡è½‰æ›
        threading.Thread(target=self.process_batch_conversion, daemon=True).start()
    
    def process_batch_conversion(self):
        """è™•ç†æ‰¹æ¬¡è½‰æ›"""
        try:
            all_text = []
            total_files = len(self.audio_files)
            self.total_elapsed_time = 0  # é‡ç½®ç´¯è¨ˆæ™‚é–“
            
            for i, file_info in enumerate(self.audio_files):
                self.current_processing_index = i
                
                # æ›´æ–°ç‹€æ…‹
                status_text = f"æ­£åœ¨è™•ç†æª”æ¡ˆ {i+1}/{total_files}: {file_info['name']}"
                self.root.after(0, self.update_record_status, status_text)
                
                # è¼‰å…¥ä¸¦è½‰æ›æª”æ¡ˆ
                text = self.convert_single_file(file_info['path'])
                
                # å–å¾—æª”æ¡ˆæŒçºŒæ™‚é–“ä¸¦ç´¯åŠ 
                file_duration = self.get_audio_duration(file_info['path'])
                
                if text:
                    # æ–°å¢æª”æ¡ˆæ¨™é¡Œ
                    section_title = f"\n{'='*50}\næª”æ¡ˆ {i+1}: {file_info['name']}"
                    if self.enable_timestamps:
                        section_title += f" (èµ·å§‹æ™‚é–“: {self.format_timestamp(self.total_elapsed_time)})"
                    section_title += f"\n{'='*50}\n"
                    
                    # è™•ç†æ–‡å­—å’Œæ™‚é–“æˆ³
                    if self.enable_timestamps:
                        # å¦‚æœä½¿ç”¨Whisperå¼•æ“ï¼Œå˜—è©¦ä½¿ç”¨ç²¾ç¢ºæ™‚é–“æˆ³
                        if self.engine_var.get() == "whisper":
                            try:
                                # é‡æ–°è¼‰å…¥æª”æ¡ˆä¸¦å–å¾—ç²¾ç¢ºæ™‚é–“æˆ³
                                audio_data = self.load_audio_file_for_whisper(file_info['path'])
                                if audio_data:
                                    formatted_text = self.get_whisper_timestamps(audio_data, self.total_elapsed_time)
                                else:
                                    formatted_text = self.add_timestamps_to_text(text, self.total_elapsed_time)
                            except Exception as e:
                                print(f"Whisperæ™‚é–“æˆ³å¤±æ•—ï¼Œä½¿ç”¨ä¼°ç®—: {e}")
                                formatted_text = self.add_timestamps_to_text(text, self.total_elapsed_time)
                        else:
                            formatted_text = self.add_timestamps_to_text(text, self.total_elapsed_time)
                        
                        all_text.append(section_title + formatted_text)
                    else:
                        all_text.append(section_title + text)
                else:
                    # è½‰æ›å¤±æ•—çš„æƒ…æ³
                    error_text = f"\n{'='*50}\næª”æ¡ˆ {i+1}: {file_info['name']}\n{'='*50}\n[è½‰æ›å¤±æ•—]\n"
                    all_text.append(error_text)
                
                # ç´¯åŠ æ™‚é–“åˆ°ä¸‹ä¸€å€‹æª”æ¡ˆ
                self.total_elapsed_time += file_duration
            
            # åˆä½µæ‰€æœ‰æ–‡å­—ä¸¦é¡¯ç¤º
            final_text = "\n".join(all_text)
            self.root.after(0, self.safe_update_result, final_text)
            self.root.after(0, self.update_record_status, f"æ‰¹æ¬¡è½‰æ›å®Œæˆ ({total_files} å€‹æª”æ¡ˆ)")
            
            # å¦‚æœå•Ÿç”¨AIæ‘˜è¦ï¼Œè‡ªå‹•ç”Ÿæˆæ‘˜è¦
            if self.enable_ai_summary and self.openai_api_key:
                self.root.after(1000, self.generate_ai_summary)  # å»¶é²1ç§’å¾Œç”Ÿæˆæ‘˜è¦
            
        except Exception as e:
            error_text = f"æ‰¹æ¬¡è½‰æ›å¤±æ•—: {e}"
            self.root.after(0, self.update_record_status, error_text)
            print(error_text)
    
    def convert_single_file(self, file_path):
        """è½‰æ›å–®ä¸€æª”æ¡ˆç‚ºæ–‡å­—"""
        try:
            # è¼‰å…¥éŸ³è¨Šæª”æ¡ˆ
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext in ['.mp3', '.mp4', '.m4a', '.flac', '.aac', '.ogg']:
                # ä½¿ç”¨pydubè½‰æ›ç‚ºWAVæ ¼å¼
                audio = AudioSegment.from_file(file_path)
                
                # å‰µå»ºè‡¨æ™‚WAVæª”æ¡ˆ
                temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                temp_wav_path = temp_wav.name
                self.temp_files.append(temp_wav_path)
                audio.export(temp_wav_path, format="wav")
                
                # è¼‰å…¥è½‰æ›å¾Œçš„æª”æ¡ˆ
                with sr.AudioFile(temp_wav_path) as source:
                    audio_data = self.recognizer.record(source)
            else:
                # ç›´æ¥è¼‰å…¥WAVæª”æ¡ˆ
                with sr.AudioFile(file_path) as source:
                    audio_data = self.recognizer.record(source)
            
            # é€²è¡ŒèªéŸ³è­˜åˆ¥
            return self.perform_recognition(audio_data)
            
        except Exception as e:
            print(f"è½‰æ›æª”æ¡ˆ {file_path} å¤±æ•—: {e}")
            return None
    
    def continuous_recording(self):
        """é€£çºŒéŒ„éŸ³æ¨¡å¼"""
        segment_count = 0
        while self.is_recording:
            # å¦‚æœæš«åœï¼Œå‰‡ç­‰å¾…
            if self.is_paused:
                time.sleep(0.1)
                continue
                
            try:
                with self.microphone as source:
                    # éŒ„è£½éŸ³è¨Šæ®µè½ï¼ˆå…è¨±è¼ƒé•·çš„éœéŸ³é–“éš”ï¼‰
                    audio = self.recognizer.listen(
                        source, 
                        timeout=1, 
                        phrase_time_limit=None  # ç§»é™¤çŸ­èªæ™‚é–“é™åˆ¶
                    )
                    
                    # æª¢æŸ¥æ˜¯å¦é‚„åœ¨éŒ„éŸ³ä¸”æœªæš«åœ
                    if self.is_recording and not self.is_paused:
                        self.recording_segments.append(audio)
                        segment_count += 1
                        
                        # æ›´æ–°ç‹€æ…‹
                        elapsed_time = time.time() - self.recording_start_time - self.total_pause_time
                        if self.pause_start_time:  # å¦‚æœæ­£åœ¨æš«åœä¸­
                            current_pause = time.time() - self.pause_start_time
                            elapsed_time -= current_pause
                        
                        status_text = f"éŒ„éŸ³ä¸­... {segment_count}æ®µ (æœ‰æ•ˆæ™‚é–“: {elapsed_time:.1f}ç§’)"
                        self.root.after(0, self.update_record_status, status_text)
                    
            except sr.WaitTimeoutError:
                # è¶…æ™‚æ™‚ç¹¼çºŒç­‰å¾…ï¼Œä¸çµæŸéŒ„éŸ³
                continue
            except Exception as e:
                if self.is_recording:  # åªåœ¨ä»åœ¨éŒ„éŸ³æ™‚é¡¯ç¤ºéŒ¯èª¤
                    print(f"éŒ„éŸ³æ®µè½éŒ¯èª¤: {e}")
                continue
        
        # åˆä½µæ‰€æœ‰éŒ„éŸ³æ®µè½
        if self.recording_segments:
            self.merge_audio_segments()
    
    def single_recording(self):
        """å–®å¥éŒ„éŸ³æ¨¡å¼"""
        try:
            # ç­‰å¾…ç›´åˆ°ä¸æ˜¯æš«åœç‹€æ…‹
            while self.is_recording and self.is_paused:
                time.sleep(0.1)
            
            if not self.is_recording:
                return
                
            with self.microphone as source:
                # å–®æ¬¡éŒ„éŸ³ï¼Œè¼ƒçŸ­çš„è¶…æ™‚æ™‚é–“
                audio = self.recognizer.listen(source, timeout=10, phrase_time_limit=10)
                
                # æª¢æŸ¥æ˜¯å¦é‚„åœ¨éŒ„éŸ³ä¸”æœªæš«åœ
                if self.is_recording and not self.is_paused:
                    self.audio_data = audio
                    
                    # è‡ªå‹•åœæ­¢éŒ„éŸ³
                    self.root.after(0, self.stop_recording)
                
        except sr.WaitTimeoutError:
            if self.is_recording:  # åªåœ¨ä»åœ¨éŒ„éŸ³æ™‚é¡¯ç¤ºè¶…æ™‚
                self.root.after(0, self.update_record_status, "éŒ„éŸ³è¶…æ™‚")
                self.root.after(0, self.stop_recording)
    
    def merge_audio_segments(self):
        """åˆä½µå¤šå€‹éŒ„éŸ³æ®µè½"""
        try:
            if not self.recording_segments:
                return
            
            if len(self.recording_segments) == 1:
                self.audio_data = self.recording_segments[0]
                self.root.after(0, self.update_record_status, "éŒ„éŸ³å®Œæˆ")
                return
            
            # å‰µå»ºè‡¨æ™‚æ–‡ä»¶ä¾†åˆä½µéŸ³è¨Š
            temp_files = []
            
            # å°‡æ¯å€‹æ®µè½ä¿å­˜ç‚ºè‡¨æ™‚æ–‡ä»¶
            for i, segment in enumerate(self.recording_segments):
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f"_segment_{i}.wav")
                try:
                    with open(temp_file.name, "wb") as f:
                        f.write(segment.get_wav_data())
                    temp_files.append(temp_file.name)
                    self.temp_files.append(temp_file.name)  # è¿½è¹¤è‡¨æ™‚æª”æ¡ˆ
                except Exception as e:
                    print(f"ä¿å­˜æ®µè½ {i} å¤±æ•—: {e}")
                    continue
            
            if not temp_files:
                print("æ²’æœ‰æœ‰æ•ˆçš„éŸ³è¨Šæ®µè½")
                return
            
            # ä½¿ç”¨pydubåˆä½µéŸ³è¨Š
            combined = AudioSegment.empty()
            for temp_file in temp_files:
                try:
                    segment_audio = AudioSegment.from_wav(temp_file)
                    combined += segment_audio
                except Exception as e:
                    print(f"è¼‰å…¥æ®µè½å¤±æ•—: {e}")
                    continue
            
            if len(combined) == 0:
                print("åˆä½µå¾ŒéŸ³è¨Šç‚ºç©º")
                return
            
            # ä¿å­˜åˆä½µçµæœ
            final_temp = tempfile.NamedTemporaryFile(delete=False, suffix="_combined.wav")
            final_temp_path = final_temp.name
            self.temp_files.append(final_temp_path)  # è¿½è¹¤è‡¨æ™‚æª”æ¡ˆ
            
            try:
                combined.export(final_temp_path, format="wav")
                
                # è¼‰å…¥åˆä½µå¾Œçš„éŸ³è¨Š
                with sr.AudioFile(final_temp_path) as source:
                    self.audio_data = self.recognizer.record(source)
                
                print(f"å·²åˆä½µ {len(self.recording_segments)} å€‹éŒ„éŸ³æ®µè½")
                status_text = f"éŒ„éŸ³å®Œæˆ (åˆä½µäº†{len(self.recording_segments)}æ®µ)"
                self.root.after(0, self.update_record_status, status_text)
                
            except Exception as e:
                print(f"åˆä½µæœ€çµ‚è™•ç†å¤±æ•—: {e}")
                # å¦‚æœåˆä½µå¤±æ•—ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹æ®µè½
                if self.recording_segments:
                    self.audio_data = self.recording_segments[0]
                    self.root.after(0, self.update_record_status, "éŒ„éŸ³å®Œæˆï¼ˆä½¿ç”¨ç¬¬ä¸€æ®µï¼‰")
            
            # æ¸…ç†æ®µè½è‡¨æ™‚æ–‡ä»¶ï¼ˆä¿ç•™æœ€çµ‚åˆä½µæª”æ¡ˆä¾›å¾ŒçºŒä½¿ç”¨ï¼‰
            for temp_file in temp_files:
                try:
                    os.unlink(temp_file)
                    if temp_file in self.temp_files:
                        self.temp_files.remove(temp_file)
                except:
                    pass
                    
        except Exception as e:
            print(f"åˆä½µéŸ³è¨Šå¤±æ•—: {e}")
            # å¦‚æœåˆä½µå¤±æ•—ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹æ®µè½
            if self.recording_segments:
                self.audio_data = self.recording_segments[0]
                self.root.after(0, self.update_record_status, "éŒ„éŸ³å®Œæˆï¼ˆåˆä½µå¤±æ•—ï¼Œä½¿ç”¨ç¬¬ä¸€æ®µï¼‰")
    
    def upload_audio_file(self):
        """ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ"""
        file_path = filedialog.askopenfilename(
            title="é¸æ“‡éŸ³è¨Šæª”æ¡ˆ",
            filetypes=[
                ("éŸ³è¨Šæª”æ¡ˆ", "*.wav *.mp3 *.mp4 *.m4a *.flac *.aac *.ogg"),
                ("WAVæª”æ¡ˆ", "*.wav"),
                ("MP3æª”æ¡ˆ", "*.mp3"),
                ("MP4æª”æ¡ˆ", "*.mp4"),
                ("æ‰€æœ‰æª”æ¡ˆ", "*.*")
            ]
        )
        
        if file_path:
            self.file_label.config(text=os.path.basename(file_path))
            
            # è¼‰å…¥éŸ³è¨Šæª”æ¡ˆ
            try:
                # æª¢æŸ¥æª”æ¡ˆæ ¼å¼ä¸¦è½‰æ›
                file_ext = os.path.splitext(file_path)[1].lower()
                
                if file_ext in ['.mp3', '.mp4', '.m4a', '.flac', '.aac', '.ogg']:
                    # ä½¿ç”¨pydubè½‰æ›ç‚ºWAVæ ¼å¼
                    audio = AudioSegment.from_file(file_path)
                    
                    # å‰µå»ºè‡¨æ™‚WAVæª”æ¡ˆ
                    temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                    temp_wav_path = temp_wav.name
                    self.temp_files.append(temp_wav_path)  # è¿½è¹¤è‡¨æ™‚æª”æ¡ˆ
                    audio.export(temp_wav_path, format="wav")
                    
                    # è¼‰å…¥è½‰æ›å¾Œçš„æª”æ¡ˆ
                    with sr.AudioFile(temp_wav_path) as source:
                        self.audio_data = self.recognizer.record(source)
                    
                else:
                    # ç›´æ¥è¼‰å…¥WAVæª”æ¡ˆ
                    with sr.AudioFile(file_path) as source:
                        self.audio_data = self.recognizer.record(source)
                
                messagebox.showinfo("æˆåŠŸ", "éŸ³è¨Šæª”æ¡ˆè¼‰å…¥æˆåŠŸ")
                
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥éŸ³è¨Šæª”æ¡ˆå¤±æ•—: {e}")
                print(f"è©³ç´°éŒ¯èª¤ä¿¡æ¯: {e}")
    
    def convert_speech_to_text(self):
        """è½‰æ›èªéŸ³ç‚ºæ–‡å­—"""
        # æª¢æŸ¥æ˜¯å¦æœ‰éŒ„éŸ³æ•¸æ“šæˆ–æª”æ¡ˆåˆ—è¡¨
        if not self.audio_data and not self.audio_files:
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆéŒ„éŸ³æˆ–æ–°å¢éŸ³è¨Šæª”æ¡ˆ")
            return
        
        self.text_result.delete(1.0, tk.END)
        
        if self.audio_files:
            # å¦‚æœæœ‰æª”æ¡ˆåˆ—è¡¨ï¼ŒåŸ·è¡Œæ‰¹æ¬¡è½‰æ›
            self.text_result.insert(tk.END, "é–‹å§‹æ‰¹æ¬¡è½‰æ›...\n")
            self.batch_convert_files()
        elif self.audio_data:
            # å¦‚æœåªæœ‰éŒ„éŸ³æ•¸æ“šï¼ŒåŸ·è¡Œå–®ä¸€è½‰æ›
            self.text_result.insert(tk.END, "æ­£åœ¨è½‰æ›éŒ„éŸ³ä¸­ï¼Œè«‹ç¨å€™...\n")
            self.root.update()
            threading.Thread(target=self.perform_single_conversion, daemon=True).start()
    
    def perform_single_conversion(self):
        """åŸ·è¡Œå–®ä¸€éŸ³è¨Šè½‰æ›"""
        try:
            text = self.perform_recognition(self.audio_data)
            if text:
                # å¦‚æœå•Ÿç”¨æ™‚é–“æˆ³ï¼Œæ·»åŠ æ™‚é–“æˆ³
                if self.enable_timestamps:
                    # å¦‚æœä½¿ç”¨Whisperå¼•æ“ï¼Œä½¿ç”¨ç²¾ç¢ºæ™‚é–“æˆ³
                    if self.engine_var.get() == "whisper":
                        try:
                            formatted_text = self.get_whisper_timestamps(self.audio_data, 0)
                        except Exception as e:
                            print(f"Whisperæ™‚é–“æˆ³å¤±æ•—ï¼Œä½¿ç”¨ä¼°ç®—: {e}")
                            formatted_text = self.add_timestamps_to_text(text, 0)
                    else:
                        formatted_text = self.add_timestamps_to_text(text, 0)  # éŒ„éŸ³å¾0é–‹å§‹
                    
                    self.root.after(0, self.safe_update_result, formatted_text)
                else:
                    self.root.after(0, self.safe_update_result, text)
                
                self.root.after(0, self.update_record_status, "è½‰æ›å®Œæˆ")
                
                # å¦‚æœå•Ÿç”¨AIæ‘˜è¦ï¼Œè‡ªå‹•ç”Ÿæˆæ‘˜è¦
                if self.enable_ai_summary and self.openai_api_key:
                    self.root.after(1000, self.generate_ai_summary)  # å»¶é²1ç§’å¾Œç”Ÿæˆæ‘˜è¦
                
            else:
                self.root.after(0, self.safe_update_result, "è½‰æ›å¤±æ•—")
                self.root.after(0, self.update_record_status, "è½‰æ›å¤±æ•—")
                
        except Exception as e:
            error_text = f"è½‰æ›å¤±æ•—: {e}"
            self.root.after(0, self.safe_update_result, error_text)
            self.root.after(0, self.update_record_status, error_text)
            print(error_text)
    
    def perform_recognition(self, audio_data):
        """åŸ·è¡ŒèªéŸ³è­˜åˆ¥ä¸¦è¿”å›æ–‡å­—"""
        try:
            engine = self.engine_var.get()
            language = self.language_var.get()
            
            if engine == "google":
                # ä½¿ç”¨GoogleèªéŸ³è­˜åˆ¥
                if language == "auto":
                    return self.recognizer.recognize_google(audio_data)
                else:
                    return self.recognizer.recognize_google(audio_data, language=language)
            
            elif engine == "whisper":
                # ä½¿ç”¨WhisperèªéŸ³è­˜åˆ¥
                if not self.whisper_model:
                    raise Exception("Whisperæ¨¡å‹æœªè¼‰å…¥")
                
                # å°‡AudioDataè½‰æ›ç‚ºè‡¨æ™‚æª”æ¡ˆ
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                temp_file_path = temp_file.name
                self.temp_files.append(temp_file_path)
                
                try:
                    with open(temp_file_path, "wb") as f:
                        f.write(audio_data.get_wav_data())
                    
                    # ä½¿ç”¨Whisperè½‰æ›
                    if self.enable_timestamps:
                        # å•Ÿç”¨æ™‚é–“æˆ³æ™‚ï¼Œå–å¾—è©³ç´°çš„segmentè³‡è¨Š
                        if language == "auto":
                            result = self.whisper_model.transcribe(temp_file_path, word_timestamps=True)
                        else:
                            lang_code = "zh" if language == "zh-TW" else "en"
                            result = self.whisper_model.transcribe(temp_file_path, language=lang_code, word_timestamps=True)
                        
                        # å¦‚æœæ˜¯æ‰¹æ¬¡è½‰æ›çš„ä¸€éƒ¨åˆ†ï¼Œè¿”å›å¸¶æœ‰segmentè³‡è¨Šçš„çµæœ
                        if hasattr(self, '_return_segments') and self._return_segments:
                            return result
                        else:
                            return result["text"]
                    else:
                        # ä¸€èˆ¬è½‰æ›
                        if language == "auto":
                            result = self.whisper_model.transcribe(temp_file_path)
                        else:
                            lang_code = "zh" if language == "zh-TW" else "en"
                            result = self.whisper_model.transcribe(temp_file_path, language=lang_code)
                        
                        return result["text"]
                
                finally:
                    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆæœƒåœ¨ç¨‹å¼çµæŸæˆ–é‡ç½®æ™‚çµ±ä¸€è™•ç†
                    pass
            
            else:
                raise Exception(f"ä¸æ”¯æ´çš„è­˜åˆ¥å¼•æ“: {engine}")
                
        except Exception as e:
            print(f"èªéŸ³è­˜åˆ¥å¤±æ•—: {e}")
            return None
    
    def update_result(self, text):
        """æ›´æ–°çµæœé¡¯ç¤ºï¼ˆä¿ç•™ç”¨æ–¼å‘å¾Œç›¸å®¹ï¼‰"""
        self.safe_update_result(text)
    
    def export_txt(self):
        """å°å‡ºç‚ºTXTæª”æ¡ˆ"""
        content = self.text_result.get(1.0, tk.END).strip()
        if not content:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å…§å®¹å¯ä»¥å°å‡º")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="å„²å­˜TXTæª”æ¡ˆ",
            defaultextension=".txt",
            filetypes=[("æ–‡å­—æª”æ¡ˆ", "*.txt"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")]
        )
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(f"èªéŸ³è½‰æ–‡å­—çµæœ\n")
                    f.write(f"è½‰æ›æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("-" * 50 + "\n")
                    f.write(content)
                messagebox.showinfo("æˆåŠŸ", f"å·²æˆåŠŸå°å‡ºè‡³: {file_path}")
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"å°å‡ºå¤±æ•—: {e}")
    
    def export_docx(self):
        """å°å‡ºç‚ºDOCXæª”æ¡ˆ"""
        content = self.text_result.get(1.0, tk.END).strip()
        if not content:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å…§å®¹å¯ä»¥å°å‡º")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="å„²å­˜DOCXæª”æ¡ˆ",
            defaultextension=".docx",
            filetypes=[("Wordæª”æ¡ˆ", "*.docx"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")]
        )
        
        if file_path:
            try:
                doc = Document()
                doc.add_heading('èªéŸ³è½‰æ–‡å­—çµæœ', 0)
                doc.add_paragraph(f'è½‰æ›æ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
                doc.add_paragraph('-' * 50)
                doc.add_paragraph(content)
                doc.save(file_path)
                messagebox.showinfo("æˆåŠŸ", f"å·²æˆåŠŸå°å‡ºè‡³: {file_path}")
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"å°å‡ºå¤±æ•—: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    root = tk.Tk()
    app = SpeechToTextApp(root)
    root.mainloop()

if __name__ == "__main__":
    main()
